{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a592d28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "from randaugment import RandAugment\n",
    "\n",
    "class ImageNet_LT(data.Dataset):\n",
    "    def __init__(self, phase, anno_path, testset, rgb_mean, rgb_std, rand_aug, output_path, logger):\n",
    "        super(ImageNet_LT, self).__init__()\n",
    "        valid_phase = ['train_l', 'train_ul', 'val', 'test']\n",
    "        assert phase in valid_phase\n",
    "        if phase == 'train_l':\n",
    "            full_phase = 'train_l'\n",
    "        elif phase == 'train_ul'\n",
    "            full_phase = 'train_ul'\n",
    "        elif phase == 'test':\n",
    "            full_phase = testset\n",
    "        else:\n",
    "            full_phase = phase\n",
    "        logger.info('====== The Current Split is : {}'.format(full_phase))\n",
    "        self.logger = logger\n",
    "\n",
    "        self.dataset_info = {}\n",
    "        self.phase = phase\n",
    "        self.rand_aug = rand_aug\n",
    "\n",
    "        # load annotation\n",
    "        self.annotations = json.load(open(anno_path))\n",
    "        self.data = self.annotations[full_phase]\n",
    "\n",
    "        # get transform\n",
    "        self.transform = self.get_data_transform(phase, rgb_mean, rgb_std)\n",
    "        \n",
    "        # load dataset category info\n",
    "        logger.info('=====> Load dataset category info')\n",
    "        self.id2cat, self.cat2id = self.annotations['id2cat'], self.annotations['cat2id']\n",
    "\n",
    "        # load all image info\n",
    "        logger.info('=====> Load image info')\n",
    "        self.img_paths, self.labels, self.attributes, self.frequencies = self.load_img_info()\n",
    "        \n",
    "        # save dataset info\n",
    "        logger.info('=====> Save dataset info')\n",
    "        self.dataset_info['cat2id'] = self.cat2id\n",
    "        self.dataset_info['id2cat'] = self.id2cat\n",
    "        self.save_dataset_info(output_path)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = self.img_paths[index]\n",
    "        label = self.labels[index]\n",
    "        rarity = self.frequencies[index]\n",
    "\n",
    "        with open(path, 'rb') as f:\n",
    "            sample = Image.open(f).convert('RGB')\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        # intra-class attribute SHOULD NOT be used during training\n",
    "        if self.phase != 'train':\n",
    "            attribute = self.attributes[index]\n",
    "            return sample, label, rarity, attribute, index\n",
    "        else:\n",
    "            return sample, label, rarity, index\n",
    "\n",
    "\n",
    "    #######################################\n",
    "    #  Load image info\n",
    "    #######################################\n",
    "    def load_img_info(self):\n",
    "        img_paths = []\n",
    "        labels = []\n",
    "        attributes = []\n",
    "        frequencies = []\n",
    "\n",
    "\n",
    "        for path, label in self.data['label'].items():\n",
    "            img_paths.append(path)\n",
    "            labels.append(int(label))\n",
    "            frequencies.append(int(self.data['frequency'][path]))\n",
    "\n",
    "            # intra-class attribute SHOULD NOT be used in training\n",
    "            if self.phase != 'train':\n",
    "                att_label = int(self.data['attribute'][path])\n",
    "                attributes.append(att_label)\n",
    "               \n",
    "        # save dataset info\n",
    "        self.dataset_info['img_paths'] = img_paths\n",
    "        self.dataset_info['labels'] = labels\n",
    "        self.dataset_info['attributes'] = attributes\n",
    "        self.dataset_info['frequencies'] = frequencies\n",
    "\n",
    "        return img_paths, labels, attributes, frequencies\n",
    " \n",
    "\n",
    "    #######################################\n",
    "    #  Save dataset info\n",
    "    #######################################\n",
    "    def save_dataset_info(self, output_path):\n",
    "\n",
    "        with open(os.path.join(output_path, 'dataset_info_{}.json'.format(self.phase)), 'w') as f:\n",
    "            json.dump(self.dataset_info, f)\n",
    "\n",
    "        del self.dataset_info\n",
    "\n",
    "\n",
    "    #######################################\n",
    "    #  transform\n",
    "    #######################################\n",
    "    def get_data_transform(self, phase, rgb_mean, rgb_std):\n",
    "        transform_info = {\n",
    "            'rgb_mean': rgb_mean,\n",
    "            'rgb_std':  rgb_std,\n",
    "        }\n",
    "\n",
    "        if phase == 'train':\n",
    "            if self.rand_aug:\n",
    "                self.logger.info('============= Using Rand Augmentation in Dataset ===========')\n",
    "                trans = transforms.Compose([\n",
    "                            transforms.RandomResizedCrop(112),\n",
    "                            transforms.RandomHorizontalFlip(),\n",
    "                            RandAugment(),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize(rgb_mean, rgb_std)\n",
    "                        ])\n",
    "                transform_info['operations'] = ['RandomResizedCrop(112)', 'RandomHorizontalFlip()', \n",
    "                                            'RandAugment()', 'ToTensor()', 'Normalize(rgb_mean, rgb_std)']\n",
    "            else:\n",
    "                self.logger.info('============= Using normal transforms in Dataset ===========')\n",
    "                trans = transforms.Compose([\n",
    "                            transforms.RandomResizedCrop(112),\n",
    "                            transforms.RandomHorizontalFlip(),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize(rgb_mean, rgb_std)\n",
    "                        ])\n",
    "                transform_info['operations'] = ['RandomResizedCrop(112)', 'RandomHorizontalFlip()', \n",
    "                                            'ToTensor()', 'Normalize(rgb_mean, rgb_std)']\n",
    "        else:\n",
    "            trans = transforms.Compose([\n",
    "                            transforms.Resize(128),\n",
    "                            transforms.CenterCrop(112),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize(rgb_mean, rgb_std)\n",
    "                        ])\n",
    "            transform_info['operations'] = ['Resize(128)', 'CenterCrop(112)', 'ToTensor()', 'Normalize(rgb_mean, rgb_std)']\n",
    "        \n",
    "        # save dataset info\n",
    "        self.dataset_info['transform_info'] = transform_info\n",
    "\n",
    "        return trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e0c03f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision\n",
    "import torch\n",
    "from torchvision.transforms import transforms\n",
    "from RandAugment import RandAugment\n",
    "from RandAugment.augmentations import CutoutDefault\n",
    "import json\n",
    "\n",
    "\n",
    "class TransformTwice:\n",
    "    def __init__(self, transform, transform2):\n",
    "        self.transform = transform\n",
    "        self.transform2 = transform2\n",
    "\n",
    "    def __call__(self, inp):\n",
    "        out1 = self.transform(inp)\n",
    "        out2 = self.transform2(inp)\n",
    "        out3 = self.transform2(inp)\n",
    "        return out1, out2, out3\n",
    "\n",
    "\n",
    "def get_imagenet_glt(anno_path, phase, img_size=112, return_strong_labeled_set=False):\n",
    "\n",
    "    assert img_size == 64 or img_size == 112, 'img size should only be 32 or 64!!!'\n",
    "    assert phase in [\"test_lt\",\"test_bl\",\"test_bbl\"]\n",
    "\n",
    "    # compute dataset mean and std\n",
    "    dataset_mean = (0.485, 0.456, 0.406)  # np.mean(base_dataset.data, axis=(0, 1, 2)) / 255\n",
    "    print(dataset_mean)\n",
    "\n",
    "    dataset_std = (0.229, 0.224, 0.225)  # np.std(base_dataset.data, axis=(0, 1, 2)) / 255\n",
    "    print(dataset_std)\n",
    "\n",
    "    # construct data augmentation\n",
    "    # Augmentations.\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(img_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(dataset_mean, dataset_std)\n",
    "    ])\n",
    "\n",
    "    transform_strong = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(img_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(dataset_mean, dataset_std)\n",
    "    ])\n",
    "    transform_strong.transforms.insert(0, RandAugment(3, 4))\n",
    "    transform_strong.transforms.append(CutoutDefault(int(img_size / 2)))\n",
    "\n",
    "    transform_val = transforms.Compose([\n",
    "        transforms.Resize(128),\n",
    "        transforms.CenterCrop(img_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(dataset_mean, dataset_std)\n",
    "    ])\n",
    "\n",
    "    train_labeled_dataset = Imagenet_GLT(anno_path, \"train_l\", img_size, transform=transform_train)\n",
    "    train_unlabeled_dataset = Imagenet_GLT(anno_path, \"train_ul\", img_size, transform=transform_strong)\n",
    "    test_dataset = Imagenet_GLT(anno_path, phase, img_size, transform=transform_val)\n",
    "\n",
    "    if return_strong_labeled_set:\n",
    "        train_strong_labeled_dataset = Imagenet_GLT(anno_path, \"train_l\", img_size, transform=transform_strong)\n",
    "        return train_labeled_dataset, train_unlabeled_dataset, test_dataset, train_strong_labeled_dataset\n",
    "    else:\n",
    "        return train_labeled_dataset, train_unlabeled_dataset, test_dataset\n",
    "\n",
    "\n",
    "class Imagenet_GLT(data.Dataset):\n",
    "    def __init__(self, anno_path, data_split=\"train_l\", imgsize=112, transform=None, target_transform=None):\n",
    "        assert imgsize == 64 or imgsize == 112, 'imgsize should only be 32 or 64'\n",
    "        assert data_split in ['train_l', 'train_ul', 'val', 'test_lt', 'test_bl', 'test_bbl'], \"Illegal phase. Should be in - ['train_l', 'train_ul', 'val', 'test_lt', 'test_bl', 'test_bbl']\"\n",
    "        self.imgsize = imgsize\n",
    "        self.data_split = data_split\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "        with open(anno_path, 'r') as fp:\n",
    "            self.annotations = json.load(fp)\n",
    "        self.data = self.annotations[data_split]\n",
    "        # Load Folder name(id) to class mappings and vice versa\n",
    "        self.id2cat, self.cat2id = self.annotations['id2cat'], self.annotations['cat2id']\n",
    "        # Load image paths and their corresponding labels, attributes and frequency categories(many, medium, few)\n",
    "        self.img_paths, self.labels, self.attributes, self.frequencies = self.load_img_info()\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, label, rarity, attribute, index) if it is any of the test sets\n",
    "            tuple: (image, label, rarity, index) if it is labelled train set\n",
    "            tuple: (image, rarity, index) if it is unlabelled train set\n",
    "        \"\"\"\n",
    "        path = self.img_paths[index]\n",
    "        label = self.labels[index]\n",
    "        rarity = self.frequencies[index]\n",
    "\n",
    "        with open(path, 'rb') as f:\n",
    "            sample = Image.open(f).convert('RGB')\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(label)\n",
    "\n",
    "        # intra-class attribute SHOULD NOT be used during training\n",
    "        if (\"train_l\" not in self.data_split) and (\"train_ul\" not in self.data_split):\n",
    "            attribute = self.attributes[index]\n",
    "            return sample, label, rarity, attribute, index\n",
    "        else:\n",
    "            return sample, label, rarity, index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def load_img_info(self):\n",
    "        img_paths = []\n",
    "        labels = []\n",
    "        attributes = []\n",
    "        frequencies = []\n",
    "\n",
    "\n",
    "        for path, label in self.data['label'].items():\n",
    "            img_paths.append(path)\n",
    "            labels.append(int(label))\n",
    "            frequencies.append(int(self.data['frequency'][path]))\n",
    "\n",
    "            # intra-class attribute SHOULD NOT be used in training\n",
    "            if self.data_split not in ['train_l', 'train_ul']:\n",
    "                att_label = int(self.data['attribute'][path])\n",
    "                attributes.append(att_label)\n",
    "\n",
    "        return img_paths, labels, attributes, frequencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5acf78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.485, 0.456, 0.406)\n",
      "(0.229, 0.224, 0.225)\n"
     ]
    }
   ],
   "source": [
    "a,b,c = get_imagenet_glt(\"./imagenet_sup_intra_lt_inter_lt_att6_new.json\", \"test_bbl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1628a82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.0000, -0.0000, -0.0000,  ..., -0.7137, -0.6623, -0.6965],\n",
       "          [-0.0000, -0.0000, -0.0000,  ..., -0.6794, -0.6452, -0.6623],\n",
       "          [-0.0000, -0.0000, -0.0000,  ..., -1.2959, -0.9534, -0.6623],\n",
       "          ...,\n",
       "          [-1.5014, -1.1418, -1.0904,  ..., -0.7479, -0.8335, -1.5699],\n",
       "          [-1.8439, -1.4672, -1.1247,  ..., -0.9020, -1.4672, -1.8610],\n",
       "          [-1.8782, -1.8268, -1.4672,  ..., -1.4672, -1.8439, -1.8782]],\n",
       " \n",
       "         [[-0.0000, -0.0000, -0.0000,  ..., -0.3901, -0.3725, -0.4076],\n",
       "          [-0.0000, -0.0000, -0.0000,  ..., -0.4076, -0.3901, -0.3901],\n",
       "          [-0.0000, -0.0000, -0.0000,  ..., -0.8627, -0.6001, -0.3725],\n",
       "          ...,\n",
       "          [-1.4405, -1.1078, -1.0728,  ..., -0.4426, -0.6001, -1.4580],\n",
       "          [-1.7556, -1.3880, -1.0903,  ..., -0.6001, -1.3354, -1.7731],\n",
       "          [-1.7906, -1.7381, -1.4055,  ..., -1.3354, -1.7556, -1.7906]],\n",
       " \n",
       "         [[-0.0000, -0.0000, -0.0000,  ..., -0.1661, -0.1661, -0.1835],\n",
       "          [-0.0000, -0.0000, -0.0000,  ..., -0.2010, -0.1661, -0.1487],\n",
       "          [-0.0000, -0.0000, -0.0000,  ..., -0.6367, -0.3578, -0.1487],\n",
       "          ...,\n",
       "          [-1.1421, -0.7413, -0.7238,  ..., -0.2010, -0.3578, -1.2293],\n",
       "          [-1.5081, -1.0898, -0.7413,  ..., -0.3753, -1.1073, -1.5430],\n",
       "          [-1.5430, -1.4907, -1.1073,  ..., -1.1073, -1.5256, -1.5430]]]),\n",
       " 0,\n",
       " 0,\n",
       " 0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "69e05ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct_attributes.json                       Untitled1.ipynb\r\n",
      "\u001b[0m\u001b[01;34mCoSSL\u001b[0m/                                        Untitled2.ipynb\r\n",
      "imagenet_sup_intra_lt_inter_lt_att6.json      Untitled.ipynb\r\n",
      "imagenet_sup_intra_lt_inter_lt_att6_new.json\r\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script is based on train_fix.py\n",
    "Here I train a resnet50 on ImageNet127_64 or ImageNet127_32 by fixmatch.\n",
    "Because I cannot run ImageNet127 itself. So I have to rerun many baselines.\n",
    "Differences:\n",
    "- model is resnet50 not wrn\n",
    "- input pipeline is replaced\n",
    "- imbalance_ratios are removed becase ImageNet127 is naturally imbalanced.\n",
    "  Instead, we always take 10% as labeled data from the dataset.\n",
    "- args.dataset is removed\n",
    "- target_disb is replaced with N_SAMPLES_PER_CLASS_T\n",
    "- log info is changed into 'Avg. Recall' and 'Test Acc.'\n",
    "Debug:\n",
    "- put wd back into the EMA\n",
    "- param.data.copy_(ema_param.data)\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "import models.resnet as models\n",
    "from dataset.fix_small_imagenet127 import get_small_imagenet\n",
    "from utils import save_checkpoint, FixMatch_Loss, WeightEMA\n",
    "from utils import Bar, Logger, AverageMeter, accuracy, mkdir_p\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch ReMixMatch Training')\n",
    "# Optimization options\n",
    "parser.add_argument('--epochs', default=500, type=int, metavar='N',\n",
    "                    help='number of total epochs to run')\n",
    "parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n",
    "                    help='manual epoch number (useful on restarts)')\n",
    "parser.add_argument('--batch-size', default=64, type=int, metavar='N',\n",
    "                    help='train batchsize')\n",
    "parser.add_argument('--mu', default=1, type=int, metavar='N',\n",
    "                    help='unlabeled bs = bs * mu')\n",
    "parser.add_argument('--lr', '--learning-rate', default=0.002, type=float,\n",
    "                    metavar='LR', help='initial learning rate')\n",
    "# Checkpoints\n",
    "parser.add_argument('--out', default='result', help='Directory to output the result')\n",
    "# Method options\n",
    "parser.add_argument('--labeled_percent', type=float, default=0.1, help='by default we take 10% labeled data')\n",
    "parser.add_argument('--img_size', type=int, default=112, help='ImageNet127_32 or ImageNet127_64')\n",
    "parser.add_argument('--val-iteration', type=int, default=500, help='Frequency for the evaluation')\n",
    "# Hyperparameters for FixMatch\n",
    "parser.add_argument('--tau', default=0.95, type=float, help='hyper-parameter for pseudo-label of FixMatch')\n",
    "parser.add_argument('--ema-decay', default=0.999, type=float)\n",
    "# Miscs\n",
    "parser.add_argument('--manualSeed', type=int, default=0, help='manual seed')\n",
    "parser.add_argument('--gpu', default='0', type=str, help='id(s) for CUDA_VISIBLE_DEVICES')\n",
    "parser.add_argument('--annotation-path', default = \"./_ImageNet_Generation/imagenet_sup_intra_lt_inter_lt_att6_new.json\", type=str, help=\"The path to the annotations json file with data splits\")\n",
    "parser.add_argument('--phase', default=\"test_bbl\", type=str, help=\"The testing phase type. One of [test_lt, test_bl, test_bbl]\")        \n",
    "\n",
    "args = parser.parse_args()\n",
    "state = {k: v for k, v in args._get_kwargs()}\n",
    "\n",
    "# Use CUDA\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# Random seed\n",
    "if args.manualSeed is None:\n",
    "    args.manualSeed = random.randint(1, 10000)\n",
    "random.seed(args.manualSeed)\n",
    "np.random.seed(args.manualSeed)\n",
    "torch.manual_seed(args.manualSeed)\n",
    "cudnn.benchmark = False\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed_all(args.manualSeed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "best_acc = 0  # best test accuracy\n",
    "num_class = 1000\n",
    "\n",
    "\n",
    "def main():\n",
    "    global best_acc\n",
    "\n",
    "    if not os.path.isdir(args.out):\n",
    "        mkdir_p(args.out)\n",
    "\n",
    "    # Data\n",
    "    print(f'==> Preparing ImageNet_GLT-{args.img_size}')\n",
    "\n",
    "    # img_size2path = {32: '/BS/yfan/nobackup/ImageNet127_32', 64: '/BS/yfan/nobackup/ImageNet127_64'}\n",
    "    tmp = get_imagenet_glt(args.annotation_path, args.phase, img_size=args.img_size, return_strong_labeled_set=False)\n",
    "    train_labeled_set, train_unlabeled_set, test_set = tmp\n",
    "\n",
    "    labeled_trainloader = data.DataLoader(train_labeled_set, batch_size=args.batch_size, shuffle=True, num_workers=0,\n",
    "                                          drop_last=True)\n",
    "    unlabeled_trainloader = data.DataLoader(train_unlabeled_set, batch_size=args.mu * args.batch_size, shuffle=True, num_workers=0,\n",
    "                                            drop_last=True)\n",
    "    test_loader = data.DataLoader(test_set, batch_size=args.batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    # Model\n",
    "    print(\"==> creating ResNet-50\")\n",
    "\n",
    "    def create_model(ema=False):\n",
    "        model = models.ResNet50(num_classes=num_class, rotation=True, classifier_bias=True)\n",
    "        model = model.cuda()\n",
    "\n",
    "        if ema:\n",
    "            for param in model.parameters():\n",
    "                param.detach_()\n",
    "\n",
    "        return model\n",
    "\n",
    "    model = create_model()\n",
    "    ema_model = create_model(ema=True)\n",
    "\n",
    "    print('Total params: %.2fM' % (sum(p.numel() for p in model.parameters())/1000000.0))\n",
    "\n",
    "    train_criterion = FixMatch_Loss()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "    ema_optimizer = WeightEMA(model, ema_model, args.lr, alpha=args.ema_decay)\n",
    "    start_epoch = 0\n",
    "\n",
    "    # Resume\n",
    "    title = 'fix-cifar-10'\n",
    "    if os.path.isfile(os.path.join(args.out, 'checkpoint.pth.tar')):\n",
    "        # Load checkpoint.\n",
    "        print('==> Resuming from checkpoint..')\n",
    "        checkpoint = torch.load(os.path.join(args.out, 'checkpoint.pth.tar'))\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        ema_model.load_state_dict(checkpoint['ema_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        logger = Logger(os.path.join(args.out, 'log.txt'), title=title, resume=True)\n",
    "    else:\n",
    "        logger = Logger(os.path.join(args.out, 'log.txt'), title=title)\n",
    "        logger.set_names(['Train Loss', 'Train Loss X', 'Train Loss U', 'Mask', 'Total Acc.', 'Used Acc.',\n",
    "                          'Test Loss', 'Avg. Recall', 'Test Acc.'])\n",
    "\n",
    "    test_accs = []\n",
    "    test_gms = []\n",
    "\n",
    "    # Main function\n",
    "    for epoch in range(start_epoch, args.epochs):\n",
    "        print('\\nEpoch: [%d | %d] LR: %f' % (epoch + 1, args.epochs, state['lr']))\n",
    "\n",
    "        # Training part\n",
    "        *train_info, = train(labeled_trainloader,\n",
    "                             unlabeled_trainloader,\n",
    "                             model, optimizer,\n",
    "                             ema_optimizer,\n",
    "                             train_criterion,\n",
    "                             epoch, use_cuda,\n",
    "                             )\n",
    "\n",
    "        # Evaluation part\n",
    "        test_loss, test_acc, test_cls, test_gm, per_cls_acc = validate(test_loader, ema_model, criterion, use_cuda, mode='Test Stats ')\n",
    "\n",
    "        # Append logger file\n",
    "        logger.append([*train_info, test_loss, per_cls_acc.mean().tolist(), test_acc])\n",
    "\n",
    "        # Save models\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'ema_state_dict': ema_model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, epoch, args.out)\n",
    "        test_accs.append(test_acc)\n",
    "        test_gms.append(test_gm)\n",
    "\n",
    "    logger.close()\n",
    "\n",
    "    # Print the final results\n",
    "    print('Mean bAcc:')\n",
    "    print(np.mean(test_accs[-20:]))\n",
    "\n",
    "    print('Mean GM:')\n",
    "    print(np.mean(test_gms[-20:]))\n",
    "\n",
    "    print('Name of saved folder:')\n",
    "    print(args.out)\n",
    "\n",
    "\n",
    "def train(labeled_trainloader, unlabeled_trainloader, model, optimizer, ema_optimizer, criterion, epoch, use_cuda):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    losses_x = AverageMeter()\n",
    "    losses_u = AverageMeter()\n",
    "    mask_prob = AverageMeter()\n",
    "    total_c = AverageMeter()\n",
    "    used_c = AverageMeter()\n",
    "    end = time.time()\n",
    "\n",
    "    bar = Bar('Training', max=args.val_iteration)\n",
    "    labeled_train_iter = iter(labeled_trainloader)\n",
    "    unlabeled_train_iter = iter(unlabeled_trainloader)\n",
    "\n",
    "    model.train()\n",
    "    for batch_idx in range(args.val_iteration):\n",
    "        try:\n",
    "            inputs_x, targets_x, _, _ = labeled_train_iter.next()\n",
    "        except:\n",
    "            labeled_train_iter = iter(labeled_trainloader)\n",
    "            inputs_x, targets_x, _, _ = labeled_train_iter.next()\n",
    "\n",
    "        try:\n",
    "            (inputs_u, inputs_u2, inputs_u3), gt_targets_u, _, _ = unlabeled_train_iter.next()\n",
    "        except:\n",
    "            unlabeled_train_iter = iter(unlabeled_trainloader)\n",
    "            (inputs_u, inputs_u2, inputs_u3), gt_targets_u, _, _ = unlabeled_train_iter.next()\n",
    "\n",
    "        # Measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        batch_size = inputs_x.size(0)\n",
    "\n",
    "        # Transform label to one-hot\n",
    "        targets_x = torch.zeros(batch_size, num_class).scatter_(1, targets_x.view(-1, 1), 1)\n",
    "        if use_cuda:\n",
    "            inputs_x, targets_x = inputs_x.cuda(), targets_x.cuda(non_blocking=True)\n",
    "            inputs_u, inputs_u2, inputs_u3 = inputs_u.cuda(), inputs_u2.cuda(), inputs_u3.cuda()\n",
    "\n",
    "        # Generate the pseudo labels\n",
    "        with torch.no_grad():\n",
    "            # Generate the pseudo labels by aggregation and sharpening\n",
    "            outputs_u, _ = model(inputs_u)\n",
    "            targets_u = torch.softmax(outputs_u, dim=1)\n",
    "\n",
    "            max_p, p_hat = torch.max(targets_u, dim=1)\n",
    "            select_mask = max_p.ge(args.tau).float()\n",
    "\n",
    "            total_acc = p_hat.cpu().eq(gt_targets_u).float().view(-1)\n",
    "            if select_mask.sum() != 0:\n",
    "                used_c.update(total_acc[select_mask != 0].mean(0).item(), select_mask.sum())\n",
    "            mask_prob.update(select_mask.mean().item())\n",
    "            total_c.update(total_acc.mean(0).item())\n",
    "\n",
    "            p_hat = torch.zeros(len(p_hat), num_class).cuda().scatter_(1, p_hat.view(-1, 1), 1)\n",
    "            select_mask = torch.cat([select_mask, select_mask], 0)\n",
    "\n",
    "        all_inputs = torch.cat([inputs_x, inputs_u2, inputs_u3], dim=0)\n",
    "        all_targets = torch.cat([targets_x, p_hat, p_hat], dim=0)\n",
    "\n",
    "        all_outputs, _ = model(all_inputs)\n",
    "        logits_x = all_outputs[:batch_size]\n",
    "        logits_u = all_outputs[batch_size:]\n",
    "\n",
    "        Lx, Lu = criterion(logits_x, all_targets[:batch_size], logits_u, all_targets[batch_size:], select_mask)\n",
    "        loss = Lx + Lu\n",
    "\n",
    "        # record loss\n",
    "        losses.update(loss.item(), inputs_x.size(0))\n",
    "        losses_x.update(Lx.item(), inputs_x.size(0))\n",
    "        losses_u.update(Lu.item(), inputs_x.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        ema_optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        bar.suffix = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | ' \\\n",
    "                      'Loss: {loss:.4f} | Loss_x: {loss_x:.4f} | Loss_u: {loss_u:.4f} | Mask: {mask:.4f}| ' \\\n",
    "                      'Use_acc: {used_acc:.4f}'.format(\n",
    "                    batch=batch_idx + 1,\n",
    "                    size=args.val_iteration,\n",
    "                    data=data_time.avg,\n",
    "                    bt=batch_time.avg,\n",
    "                    total=bar.elapsed_td,\n",
    "                    eta=bar.eta_td,\n",
    "                    loss=losses.avg,\n",
    "                    loss_x=losses_x.avg,\n",
    "                    loss_u=losses_u.avg,\n",
    "                    mask=mask_prob.avg,\n",
    "                    used_acc=used_c.avg,\n",
    "                    )\n",
    "        bar.next()\n",
    "    bar.finish()\n",
    "\n",
    "    return (losses.avg, losses_x.avg, losses_u.avg, mask_prob.avg, total_c.avg, used_c.avg)\n",
    "\n",
    "\n",
    "def validate(valloader, model, criterion, use_cuda, mode):\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    bar = Bar(f'{mode}', max=len(valloader))\n",
    "\n",
    "    classwise_correct = torch.zeros(num_class)\n",
    "    classwise_num = torch.zeros(num_class)\n",
    "    section_acc = torch.zeros(3)\n",
    "\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets, _, _, _) in enumerate(valloader):\n",
    "            # measure data loading time\n",
    "            data_time.update(time.time() - end)\n",
    "            y_true.extend(targets.tolist())\n",
    "\n",
    "            if use_cuda:\n",
    "                inputs, targets = inputs.cuda(), targets.cuda(non_blocking=True)\n",
    "            # compute output\n",
    "            outputs, _ = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec1, prec5 = accuracy(outputs, targets, topk=(1, 5))\n",
    "            losses.update(loss.item(), inputs.size(0))\n",
    "            top1.update(prec1.item(), inputs.size(0))\n",
    "            top5.update(prec5.item(), inputs.size(0))\n",
    "\n",
    "            # classwise prediction\n",
    "            pred_label = outputs.max(1)[1]\n",
    "            y_pred.extend(pred_label.tolist())\n",
    "            pred_mask = (targets == pred_label).float()\n",
    "            for i in range(num_class):\n",
    "                class_mask = (targets == i).float()\n",
    "\n",
    "                classwise_correct[i] += (class_mask * pred_mask).sum()\n",
    "                classwise_num[i] += class_mask.sum()\n",
    "\n",
    "             # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            # plot progress\n",
    "            bar.suffix  = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | ' \\\n",
    "                          'Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}'.format(\n",
    "                        batch=batch_idx + 1,\n",
    "                        size=len(valloader),\n",
    "                        data=data_time.avg,\n",
    "                        bt=batch_time.avg,\n",
    "                        total=bar.elapsed_td,\n",
    "                        eta=bar.eta_td,\n",
    "                        loss=losses.avg,\n",
    "                        top1=top1.avg,\n",
    "                        top5=top5.avg,\n",
    "                        )\n",
    "            bar.next()\n",
    "        bar.finish()\n",
    "\n",
    "    # Major, Neutral, Minor\n",
    "    section_num = int(num_class / 3)\n",
    "    classwise_acc = (classwise_correct / classwise_num)\n",
    "    section_acc[0] = classwise_acc[:section_num].mean()\n",
    "    section_acc[2] = classwise_acc[-1 * section_num:].mean()\n",
    "    section_acc[1] = classwise_acc[section_num:-1 * section_num].mean()\n",
    "    GM = 1\n",
    "    for i in range(num_class):\n",
    "        if classwise_acc[i] == 0:\n",
    "            # To prevent the N/A values, we set the minimum value as 0.001\n",
    "            GM *= (1/(100 * num_class)) ** (1/num_class)\n",
    "        else:\n",
    "            GM *= (classwise_acc[i]) ** (1/num_class)\n",
    "\n",
    "    return (losses.avg, top1.avg, section_acc.numpy(), GM, classwise_acc)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "865180d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.Tensor(np.arange(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df451201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if(len(a.shape)!=2):\n",
    "    a = a.view(-1,5)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11553e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script should be used after the training of the train_samll_imagenet127_fix.py\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import json\n",
    "import copy\n",
    "import time\n",
    "from PIL import Image\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data.sampler import BatchSampler\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import models.resnet as models\n",
    "from dataset.fix_small_imagenet127 import get_small_imagenet\n",
    "\n",
    "from utils import Bar, Logger, AverageMeter, accuracy, mkdir_p, \\\n",
    "    get_weighted_sampler, make_imb_data, save_checkpoint, FixMatch_Loss\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch FixMatch Training')\n",
    "# Optimization options\n",
    "parser.add_argument('--epochs', default=400, type=int, metavar='N',\n",
    "                    help='number of total epochs to run')\n",
    "parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n",
    "                    help='manual epoch number (useful on restarts)')\n",
    "parser.add_argument('--batch-size', default=64, type=int, metavar='N',\n",
    "                    help='train batchsize')\n",
    "parser.add_argument('--lr', '--learning-rate', default=0.002, type=float,\n",
    "                    metavar='LR', help='initial learning rate')\n",
    "parser.add_argument('--lr_tfe', default=0.002, type=float)\n",
    "parser.add_argument('--wd_tfe', default=5e-4, type=float)\n",
    "parser.add_argument('--warm_tfe', default=10, type=int)\n",
    "# Checkpoints\n",
    "parser.add_argument('--resume', type=str, metavar='PATH', help='path to latest checkpoint (default: none)')\n",
    "parser.add_argument('--out', default='result', help='Directory to output the result')\n",
    "# Method options\n",
    "parser.add_argument('--labeled_percent', type=float, default=0.1, help='by default we take 10% labeled data')\n",
    "parser.add_argument('--img_size', type=int, default=32, help='ImageNet127_32 or ImageNet127_64')\n",
    "parser.add_argument('--val-iteration', type=int, default=500, help='Frequency for the evaluation')\n",
    "# Hyperparameters for FixMatch\n",
    "parser.add_argument('--tau', default=0.95, type=float, help='hyper-parameter for pseudo-label of FixMatch')\n",
    "parser.add_argument('--ema-decay', default=0.999, type=float)\n",
    "parser.add_argument('--max_lam', default=0.8, type=float)\n",
    "# Miscs\n",
    "parser.add_argument('--manualSeed', type=int, default=0, help='manual seed')\n",
    "# Device options\n",
    "parser.add_argument('--gpu', default='0', type=str, help='id(s) for CUDA_VISIBLE_DEVICES')\n",
    "\n",
    "args = parser.parse_args()\n",
    "state = {k: v for k, v in args._get_kwargs()}\n",
    "\n",
    "# Use CUDA\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# Random seed\n",
    "if args.manualSeed is None:\n",
    "    args.manualSeed = random.randint(1, 10000)\n",
    "random.seed(args.manualSeed)\n",
    "np.random.seed(args.manualSeed)\n",
    "torch.manual_seed(args.manualSeed)\n",
    "cudnn.benchmark = False\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed_all(args.manualSeed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "best_acc = 0  # best test accuracy\n",
    "num_class = 127\n",
    "\n",
    "\n",
    "class merge_two_datasets(data.Dataset):\n",
    "    def __init__(self, data1, data2, targets1, targets2,\n",
    "                 transform=None, target_transform=None):\n",
    "        self.data = copy.deepcopy(np.concatenate([data1, data2], axis=0))\n",
    "        self.targets = copy.deepcopy(np.concatenate([targets1, targets2], axis=0))\n",
    "        assert len(self.data) == len(self.targets)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.data[index], self.targets[index]\n",
    "        img = Image.fromarray(img)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target, index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "def main():\n",
    "    global best_acc\n",
    "\n",
    "    if not os.path.isdir(args.out):\n",
    "        mkdir_p(args.out)\n",
    "\n",
    "    # Data\n",
    "    print(f'==> Preparing imbalanced ImageNet127-{args.img_size}')\n",
    "\n",
    "    img_size2path = {32: '/BS/yfan/nobackup/ImageNet127_32', 64: '/BS/yfan/nobackup/ImageNet127_64'}\n",
    "    tmp = get_small_imagenet(img_size2path[args.img_size], args.img_size, labeled_percent=args.labeled_percent,\n",
    "                             seed=args.manualSeed, return_strong_labeled_set=True)\n",
    "    target_disb, train_labeled_set, train_unlabeled_set, test_set, _ = tmp\n",
    "\n",
    "    N_SAMPLES_PER_CLASS = [0 for _ in range(num_class)]\n",
    "    for l in train_labeled_set.targets:\n",
    "        N_SAMPLES_PER_CLASS[l] += 1\n",
    "    print(N_SAMPLES_PER_CLASS)\n",
    "\n",
    "    crt_labeled_set = copy.deepcopy(train_labeled_set)\n",
    "    crt_full_set = merge_two_datasets(crt_labeled_set.data, train_unlabeled_set.data, crt_labeled_set.targets,\n",
    "                                      train_unlabeled_set.targets, transform=crt_labeled_set.transform)\n",
    "\n",
    "    labeled_trainloader = data.DataLoader(train_labeled_set, batch_size=args.batch_size, shuffle=True, num_workers=8,\n",
    "                                          drop_last=True)\n",
    "    unlabeled_trainloader = data.DataLoader(train_unlabeled_set, batch_size=args.batch_size, shuffle=True, num_workers=8,\n",
    "                                            drop_last=True)\n",
    "    crt_full_loader = data.DataLoader(crt_full_set, batch_size=args.batch_size, shuffle=True, num_workers=8,\n",
    "                                            drop_last=True)\n",
    "    test_loader = data.DataLoader(test_set, batch_size=100, shuffle=False, num_workers=4)\n",
    "\n",
    "    # Model\n",
    "    print(\"==> creating WRN-28-2\")\n",
    "\n",
    "    def create_model(ema=False, clf_bias=True):\n",
    "        model = models.ResNet50(num_classes=num_class, rotation=True, classifier_bias=clf_bias)\n",
    "        model = model.cuda()\n",
    "\n",
    "        if ema:\n",
    "            for param in model.parameters():\n",
    "                param.detach_()\n",
    "\n",
    "        return model\n",
    "\n",
    "    model = create_model(clf_bias=True)\n",
    "    ema_model = create_model(ema=True, clf_bias=True)\n",
    "    print('    Total params: %.2fM' % (sum(p.numel() for p in model.parameters()) / 1000000.0))\n",
    "    train_criterion = FixMatch_Loss()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "    ema_optimizer = WeightEMA(model, ema_model, alpha=args.ema_decay)\n",
    "    start_epoch = 0\n",
    "\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    assert os.path.isfile(args.resume), 'Error: no checkpoint directory found!'\n",
    "    checkpoint = torch.load(args.resume)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    ema_model.load_state_dict(checkpoint['ema_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "    for group in optimizer.param_groups:\n",
    "        group['weight_decay'] = 0.02 * args.lr\n",
    "    logger = Logger(os.path.join(args.out, 'log.txt'), title='fix-cifar')\n",
    "    logger.set_names(['Train Loss', 'Train Loss X', 'Train Loss U', 'Train Loss Teacher', 'Mask', 'Total Acc.', 'Used Acc.', 'Teacher Acc.',\n",
    "                      'Test Loss', 'Test Acc.'])\n",
    "\n",
    "    teacher_head = nn.Linear(model.output.in_features, num_class, bias=True).cuda()\n",
    "    ema_teacher = nn.Linear(model.output.in_features, num_class, bias=True).cuda()\n",
    "    for param in ema_teacher.parameters():\n",
    "        param.detach_()\n",
    "    wd_params, non_wd_params = [], []\n",
    "    for name, param in teacher_head.named_parameters():\n",
    "        if 'bn' in name or 'bias' in name:\n",
    "            non_wd_params.append(param)\n",
    "        else:\n",
    "            wd_params.append(param)\n",
    "    param_list = [{'params': wd_params, 'weight_decay': args.wd_tfe}, {'params': non_wd_params, 'weight_decay': 0}]\n",
    "\n",
    "    teacher_optimizer = optim.Adam(param_list, lr=args.lr_tfe)\n",
    "    ema_teacher_optimizer = WeightEMA(teacher_head, ema_teacher, alpha=args.ema_decay)\n",
    "\n",
    "    # TFE warmup\n",
    "    init_teacher, init_ema_teacher = classifier_warmup(copy.deepcopy(ema_model), crt_labeled_set, crt_full_set,\n",
    "                                                       N_SAMPLES_PER_CLASS, num_class, use_cuda)\n",
    "    teacher_head.weight.data.copy_(init_teacher.output.weight.data)\n",
    "    teacher_head.bias.data.copy_(init_teacher.output.bias.data)\n",
    "    ema_teacher.weight.data.copy_(init_ema_teacher.output.weight.data)\n",
    "    ema_teacher.bias.data.copy_(init_ema_teacher.output.bias.data)\n",
    "\n",
    "    # Main function\n",
    "    test_accs = []\n",
    "    for epoch in range(start_epoch, args.epochs):\n",
    "        print('\\nEpoch: [%d | %d] LR: %f' % (epoch + 1, args.epochs, state['lr']))\n",
    "\n",
    "        # Construct balanced dataset\n",
    "        class_balanced_disb = torch.Tensor(make_imb_data(30000, num_class, 1))\n",
    "        class_balanced_disb = class_balanced_disb / class_balanced_disb.sum()\n",
    "        sampler_x = get_weighted_sampler(class_balanced_disb, torch.Tensor(N_SAMPLES_PER_CLASS), crt_labeled_set.targets)\n",
    "        batch_sampler_x = BatchSampler(sampler_x, batch_size=args.batch_size, drop_last=True)\n",
    "        crt_labeled_loader = data.DataLoader(crt_labeled_set, batch_sampler=batch_sampler_x, num_workers=8)\n",
    "\n",
    "        # Training part\n",
    "        *train_info, = train(labeled_trainloader, unlabeled_trainloader, model, ema_model, optimizer, ema_optimizer,\n",
    "                             crt_labeled_loader, crt_full_loader, teacher_head, ema_teacher, teacher_optimizer, ema_teacher_optimizer,\n",
    "                             train_criterion, epoch, use_cuda, N_SAMPLES_PER_CLASS)\n",
    "\n",
    "        # Evaluation part\n",
    "        test_loss, test_acc, *_ = validate_teacher(test_loader, ema_model, ema_teacher, criterion, use_cuda, mode='Test')\n",
    "\n",
    "        # Append logger file\n",
    "        logger.append([*train_info, test_loss, test_acc])\n",
    "\n",
    "        # Save models\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'ema_state_dict': ema_model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'teacher_optimizer': teacher_optimizer.state_dict(),\n",
    "            'teacher_head': teacher_head.state_dict(),\n",
    "            'ema_teacher': ema_teacher.state_dict(),\n",
    "        }, epoch + 1, args.out)\n",
    "        test_accs.append(test_acc)\n",
    "\n",
    "    logger.close()\n",
    "\n",
    "    # Print the final results\n",
    "    print('Mean bAcc:')\n",
    "    print(np.mean(test_accs[-20:]))\n",
    "\n",
    "    print('Name of saved folder:')\n",
    "    print(args.out)\n",
    "\n",
    "\n",
    "def classifier_warmup(model, train_labeled_set, train_unlabeled_set, N_SAMPLES_PER_CLASS, num_class, use_cuda):\n",
    "\n",
    "    # define hypers for cRT\n",
    "    val_iteration = args.val_iteration\n",
    "    epochs = args.warm_tfe\n",
    "    lr = args.lr_tfe\n",
    "    ema_decay = args.ema_decay\n",
    "    weight_decay = args.wd_tfe\n",
    "    batch_size = args.batch_size\n",
    "\n",
    "    # construct dataloaders for TFE\n",
    "    class_balanced_disb = torch.Tensor(make_imb_data(30000, num_class, 1))\n",
    "    class_balanced_disb = class_balanced_disb / class_balanced_disb.sum()\n",
    "    sampler_x = get_weighted_sampler(class_balanced_disb, torch.Tensor(N_SAMPLES_PER_CLASS), train_labeled_set.targets)\n",
    "    batch_sampler_x = BatchSampler(sampler_x, batch_size=batch_size, drop_last=True)\n",
    "    labeled_trainloader = data.DataLoader(train_labeled_set, batch_sampler=batch_sampler_x, num_workers=8)\n",
    "    unlabeled_trainloader = data.DataLoader(train_unlabeled_set, batch_size=batch_size,\n",
    "                                            shuffle=False, num_workers=8, drop_last=False)\n",
    "\n",
    "    tfe_model = weight_imprint(copy.deepcopy(model), train_labeled_set, num_class)\n",
    "\n",
    "    # fix the feature extractor and reinitialize the classifier\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    model.output.reset_parameters()\n",
    "    for param in model.output.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    ema_model = copy.deepcopy(model)\n",
    "    for param in ema_model.parameters():\n",
    "        param.detach_()\n",
    "    ema_optimizer = WeightEMA(model, ema_model, alpha=ema_decay)\n",
    "\n",
    "    wd_params, non_wd_params = [], []\n",
    "    for name, param in model.output.named_parameters():\n",
    "        if 'bn' in name or 'bias' in name:\n",
    "            non_wd_params.append(param)  # bn.weight, bn.bias and classifier.bias, conv2d.bias\n",
    "        else:\n",
    "            wd_params.append(param)\n",
    "    param_list = [{'params': wd_params, 'weight_decay': weight_decay}, {'params': non_wd_params, 'weight_decay': 0}]\n",
    "    print('    Total params: %.2fM' % (sum(p.numel() for p in model.output.parameters()) / 1000000.0))\n",
    "\n",
    "    optimizer = optim.Adam(param_list, lr=lr)\n",
    "    \n",
    "    # Main function\n",
    "    for epoch in range(epochs):\n",
    "        print('\\ncRT: Epoch: [%d | %d] LR: %f' % (epoch + 1, epochs, optimizer.param_groups[0]['lr']))\n",
    "        classifier_train(labeled_trainloader, unlabeled_trainloader, model, optimizer, None, ema_optimizer,\n",
    "                         tfe_model, N_SAMPLES_PER_CLASS, val_iteration, use_cuda)\n",
    "\n",
    "    return model, ema_model\n",
    "\n",
    "\n",
    "def weight_imprint(model, labeled_set, num_classes):\n",
    "    model = model.cuda()\n",
    "    model.eval()\n",
    "\n",
    "    labeledloader = torch.utils.data.DataLoader(labeled_set, batch_size=100, shuffle=False, num_workers=0, drop_last=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        bar = Bar('Processing imprinting...', max=len(labeledloader))\n",
    "        for batch_idx, (inputs, targets, _) in enumerate(labeledloader):\n",
    "            inputs = inputs.cuda()\n",
    "            _, _, features = model(inputs, True)\n",
    "            output = features.squeeze()   # Note: a flatten is needed here\n",
    "\n",
    "            if batch_idx == 0:\n",
    "                output_stack = output.cpu()\n",
    "                target_stack = targets\n",
    "            else:\n",
    "                output_stack = torch.cat((output_stack, output.cpu()), 0)\n",
    "                target_stack = torch.cat((target_stack, targets), 0)\n",
    "\n",
    "            bar.suffix = '({batch}/{size}'.format(batch=batch_idx + 1, size=len(labeledloader))\n",
    "            bar.next()\n",
    "        bar.finish()\n",
    "\n",
    "    new_weight = torch.zeros(num_classes, model.output.in_features)\n",
    "    for i in range(num_classes):\n",
    "        tmp = output_stack[target_stack == i].mean(0)\n",
    "        new_weight[i] = tmp / tmp.norm(p=2)\n",
    "    model.output = torch.nn.Linear(model.output.in_features, num_classes, bias=False).cuda()\n",
    "    model.output.weight.data = new_weight.cuda()\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def classifier_train(labeled_loader, unlabeled_loader, model, optimizer, scheduler, ema_optimizer,\n",
    "                     tfe_model, num_samples_per_class, val_iteration, use_cuda):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    train_acc = AverageMeter()\n",
    "    end = time.time()\n",
    "\n",
    "    bar = Bar('Training', max=val_iteration)\n",
    "    labeled_train_iter = iter(labeled_loader)\n",
    "    unlabeled_train_iter = iter(unlabeled_loader)\n",
    "\n",
    "    model.eval()\n",
    "    tfe_model.eval()\n",
    "\n",
    "    tfe_prob = [(max(num_samples_per_class) - i) / max(num_samples_per_class) for i in num_samples_per_class]\n",
    "\n",
    "    for batch_idx in range(args.val_iteration):\n",
    "        try:\n",
    "            inputs_x, targets_x, _ = labeled_train_iter.next()\n",
    "        except:\n",
    "            labeled_train_iter = iter(labeled_loader)\n",
    "            inputs_x, targets_x, _ = labeled_train_iter.next()\n",
    "\n",
    "        try:\n",
    "            input_u, targets_u, _ = unlabeled_train_iter.next()\n",
    "        except:\n",
    "            unlabeled_train_iter = iter(unlabeled_loader)\n",
    "            input_u, targets_u, _ = unlabeled_train_iter.next()\n",
    "\n",
    "        # Measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if use_cuda:\n",
    "            inputs_x, targets_x = inputs_x.cuda(), targets_x.cuda(non_blocking=True)  # targets are one-hot\n",
    "            input_u = input_u.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            _, _, crt_feat_x = tfe_model(inputs_x, return_feature=True)\n",
    "            crt_feat_x = crt_feat_x.squeeze()\n",
    "            _, _, crt_feat_u = tfe_model(input_u, return_feature=True)\n",
    "            crt_feat_u = crt_feat_u.squeeze()\n",
    "\n",
    "            new_feat_list = []\n",
    "            new_target_list = []\n",
    "            for x, label_x, u in zip(crt_feat_x, targets_x, crt_feat_u[:len(targets_x)]):\n",
    "                if random.random() < tfe_prob[label_x]:\n",
    "                    lam = np.random.uniform(args.max_lam, 1., size=1)\n",
    "                    lam = torch.FloatTensor(lam).cuda()\n",
    "\n",
    "                    new_feat = lam * x + (1 - lam) * u\n",
    "                    new_target = label_x\n",
    "                else:\n",
    "                    new_feat = x\n",
    "                    new_target = label_x\n",
    "                new_feat_list.append(new_feat)\n",
    "                new_target_list.append(new_target)\n",
    "            new_feat_tensor = torch.stack(new_feat_list, dim=0)  # [64, 128]\n",
    "            new_target_tensor = torch.stack(new_target_list, dim=0)  # [64,]\n",
    "\n",
    "        logits = model.output(new_feat_tensor)\n",
    "        loss = F.cross_entropy(logits, new_target_tensor)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        ema_optimizer.step()\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        # record loss\n",
    "        acc = (torch.argmax(logits, dim=1) == new_target_tensor).float().mean()\n",
    "        losses.update(loss.item(), inputs_x.size(0))\n",
    "        train_acc.update(acc.item(), inputs_x.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        bar.suffix = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | ' \\\n",
    "                      'Loss: {loss:.4f} | Train_Acc: {train_acc:.4f}'.format(\n",
    "                    batch=batch_idx + 1,\n",
    "                    size=args.val_iteration,\n",
    "                    data=data_time.avg,\n",
    "                    bt=batch_time.avg,\n",
    "                    total=bar.elapsed_td,\n",
    "                    eta=bar.eta_td,\n",
    "                    loss=losses.avg,\n",
    "                    train_acc=train_acc.avg,\n",
    "                    )\n",
    "        bar.next()\n",
    "    bar.finish()\n",
    "\n",
    "    return (losses.avg, train_acc.avg)\n",
    "\n",
    "\n",
    "def train(labeled_trainloader, unlabeled_trainloader, model, ema_model, optimizer, ema_optimizer,\n",
    "          crt_labeled_loader, crt_full_loader, teacher_head, ema_teacher, teacher_optimizer, ema_teacher_optimizer,\n",
    "          criterion, epoch, use_cuda, num_labeled_data_per_class):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    losses_x = AverageMeter()\n",
    "    losses_u = AverageMeter()\n",
    "    losses_teacher = AverageMeter()\n",
    "    mask_prob = AverageMeter()\n",
    "    total_c = AverageMeter()\n",
    "    used_c = AverageMeter()\n",
    "    teacher_acc = AverageMeter()\n",
    "    end = time.time()\n",
    "\n",
    "    bar = Bar('Training', max=args.val_iteration)\n",
    "    labeled_train_iter = iter(labeled_trainloader)\n",
    "    unlabeled_train_iter = iter(unlabeled_trainloader)\n",
    "    crt_labeled_iter = iter(crt_labeled_loader)\n",
    "    crt_full_iter = iter(crt_full_loader)\n",
    "\n",
    "    model.train()\n",
    "    ema_model.eval()\n",
    "\n",
    "    tfe_prob = [(max(num_labeled_data_per_class) - i) / max(num_labeled_data_per_class) for i in num_labeled_data_per_class]\n",
    "    for batch_idx in range(args.val_iteration):\n",
    "        try:\n",
    "            inputs_x, targets_x, _ = labeled_train_iter.next()\n",
    "        except:\n",
    "            labeled_train_iter = iter(labeled_trainloader)\n",
    "            inputs_x, targets_x, _ = labeled_train_iter.next()\n",
    "\n",
    "        try:\n",
    "            (inputs_u, inputs_u2, inputs_u3), gt_targets_u, idx_u = unlabeled_train_iter.next()\n",
    "        except:\n",
    "            unlabeled_train_iter = iter(unlabeled_trainloader)\n",
    "            (inputs_u, inputs_u2, inputs_u3), gt_targets_u, idx_u = unlabeled_train_iter.next()\n",
    "\n",
    "        try:\n",
    "            crt_input_x, crt_targets_x, _ = crt_labeled_iter.next()\n",
    "        except:\n",
    "            crt_labeled_iter = iter(crt_labeled_loader)\n",
    "            crt_input_x, crt_targets_x, _ = crt_labeled_iter.next()\n",
    "\n",
    "        try:\n",
    "            crt_input_u, crt_targets_u, _ = crt_full_iter.next()\n",
    "        except:\n",
    "            crt_full_iter = iter(crt_full_loader)\n",
    "            crt_input_u, crt_targets_u, _ = crt_full_iter.next()\n",
    "\n",
    "        # Measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        batch_size = inputs_x.size(0)\n",
    "\n",
    "        # Transform label to one-hot\n",
    "        targets_x = torch.zeros(batch_size, num_class).scatter_(1, targets_x.view(-1, 1), 1)\n",
    "        crt_targets_x = torch.zeros(batch_size, num_class).scatter_(1, crt_targets_x.view(-1, 1), 1)\n",
    "        # crt_targets_u = torch.zeros(batch_size, num_class).scatter_(1, crt_targets_u.view(-1, 1), 1)\n",
    "        if use_cuda:\n",
    "            inputs_x, targets_x = inputs_x.cuda(), targets_x.cuda(non_blocking=True)\n",
    "            inputs_u, inputs_u2, inputs_u3 = inputs_u.cuda(), inputs_u2.cuda(), inputs_u3.cuda()\n",
    "            crt_input_x, crt_input_u, crt_targets_x = crt_input_x.cuda(), crt_input_u.cuda(), crt_targets_x.cuda()\n",
    "\n",
    "        # Generate the pseudo labels\n",
    "        with torch.no_grad():\n",
    "            # Generate the pseudo labels by ema_model and ema_teacher\n",
    "            _, _, feature_u = ema_model(inputs_u, return_feature=True)\n",
    "            outputs_u = teacher_head(feature_u.squeeze())\n",
    "            targets_u = torch.softmax(outputs_u, dim=1)\n",
    "\n",
    "            max_p, p_hat = torch.max(targets_u, dim=1)\n",
    "            select_mask = max_p.ge(args.tau).float()\n",
    "            total_acc = p_hat.cpu().eq(gt_targets_u).float().view(-1)\n",
    "            if select_mask.sum() != 0:\n",
    "                used_c.update(total_acc[select_mask != 0].mean(0).item(), select_mask.sum())\n",
    "            mask_prob.update(select_mask.mean().item())\n",
    "            total_c.update(total_acc.mean(0).item())\n",
    "\n",
    "            p_hat = torch.zeros(batch_size, num_class).cuda().scatter_(1, p_hat.view(-1, 1), 1)\n",
    "            select_mask = torch.cat([select_mask, select_mask], 0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            _, _, crt_feat_x = ema_model(crt_input_x, return_feature=True)\n",
    "            crt_feat_x = crt_feat_x.squeeze()\n",
    "\n",
    "            _, _, crt_feat_u = ema_model(crt_input_u, return_feature=True)\n",
    "            crt_feat_u = crt_feat_u.squeeze()\n",
    "\n",
    "            new_feat_list = []\n",
    "            new_target_list = []\n",
    "            for x, label_x, u in zip(crt_feat_x, crt_targets_x, crt_feat_u[:len(crt_targets_x)]):\n",
    "                if random.random() < tfe_prob[label_x.argmax()]:\n",
    "                    lam = np.random.uniform(args.max_lam, 1., size=1)\n",
    "                    lam = torch.FloatTensor(lam).cuda()\n",
    "\n",
    "                    new_feat = lam * x + (1 - lam) * u\n",
    "                    new_target = label_x\n",
    "                else:\n",
    "                    new_feat = x\n",
    "                    new_target = label_x\n",
    "                new_feat_list.append(new_feat)\n",
    "                new_target_list.append(new_target)\n",
    "            new_feat_tensor = torch.stack(new_feat_list, dim=0)  # [64, 128]\n",
    "            new_target_tensor = torch.stack(new_target_list, dim=0)  # [64, 10]\n",
    "\n",
    "        teacher_logits = teacher_head(new_feat_tensor)\n",
    "        teacher_loss = -torch.mean(torch.sum(F.log_softmax(teacher_logits, dim=1) * new_target_tensor, dim=1))\n",
    "        teacher_optimizer.zero_grad()\n",
    "        teacher_loss.backward()\n",
    "        teacher_optimizer.step()\n",
    "        ema_teacher_optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            acc = (torch.argmax(teacher_logits, dim=1) == torch.argmax(crt_targets_x, dim=1)).float().mean()\n",
    "            teacher_acc.update(acc.item(), crt_targets_x.size(0))\n",
    "            teacher_acc.update(acc.item(), crt_targets_x.size(0))\n",
    "            losses_teacher.update(teacher_loss.item(), crt_targets_x.size(0))\n",
    "\n",
    "        all_inputs = torch.cat([inputs_x, inputs_u2, inputs_u3], dim=0)\n",
    "        all_targets = torch.cat([targets_x, p_hat, p_hat], dim=0)\n",
    "\n",
    "        all_outputs, _ = model(all_inputs)\n",
    "        logits_x = all_outputs[:batch_size]\n",
    "        logits_u = all_outputs[batch_size:]\n",
    "\n",
    "        Lx, Lu = criterion(logits_x, all_targets[:batch_size], logits_u, all_targets[batch_size:], select_mask)\n",
    "        loss = Lx + Lu\n",
    "\n",
    "        # record loss\n",
    "        losses.update(loss.item(), inputs_x.size(0))\n",
    "        losses_x.update(Lx.item(), inputs_x.size(0))\n",
    "        losses_u.update(Lu.item(), inputs_x.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        ema_optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        bar.suffix = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | ' \\\n",
    "                     'Loss: {loss:.4f} | Loss_x: {loss_x:.4f} | Loss_u: {loss_u:.4f} | Loss_t: {loss_t:.4f} |' \\\n",
    "                     'Mask: {mask:.4f}| Use_acc: {used_acc:.4f} | teacher_acc: {teacher_acc:.4f}'.format(\n",
    "                    batch=batch_idx + 1,\n",
    "                    size=args.val_iteration,\n",
    "                    data=data_time.avg,\n",
    "                    bt=batch_time.avg,\n",
    "                    total=bar.elapsed_td,\n",
    "                    eta=bar.eta_td,\n",
    "                    loss=losses.avg,\n",
    "                    loss_x=losses_x.avg,\n",
    "                    loss_u=losses_u.avg,\n",
    "                    loss_t=losses_teacher.avg,\n",
    "                    mask=mask_prob.avg,\n",
    "                    used_acc=used_c.avg,\n",
    "                    teacher_acc=teacher_acc.avg,\n",
    "                    )\n",
    "        bar.next()\n",
    "    bar.finish()\n",
    "\n",
    "    return (losses.avg, losses_x.avg, losses_u.avg, losses_teacher.avg, mask_prob.avg, total_c.avg, used_c.avg, teacher_acc.avg)\n",
    "\n",
    "\n",
    "def validate_teacher(valloader, model, head, criterion, use_cuda, mode):\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    bar = Bar(f'{mode}', max=len(valloader))\n",
    "\n",
    "    classwise_correct = torch.zeros(num_class).cuda()\n",
    "    classwise_num = torch.zeros(num_class).cuda()\n",
    "    section_acc = torch.zeros(3).cuda()\n",
    "\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets, _) in enumerate(valloader):\n",
    "            # measure data loading time\n",
    "            data_time.update(time.time() - end)\n",
    "            y_true.extend(targets.tolist())\n",
    "\n",
    "            if use_cuda:\n",
    "                inputs, targets = inputs.cuda(), targets.cuda(non_blocking=True)\n",
    "            # compute output\n",
    "            _, _, feats = model(inputs, return_feature=True)\n",
    "            outputs = head(feats.squeeze())\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec1, prec5 = accuracy(outputs, targets, topk=(1, 5))\n",
    "            losses.update(loss.item(), inputs.size(0))\n",
    "            top1.update(prec1.item(), inputs.size(0))\n",
    "            top5.update(prec5.item(), inputs.size(0))\n",
    "\n",
    "            # classwise prediction\n",
    "            pred_label = outputs.max(1)[1]\n",
    "            y_pred.extend(pred_label.tolist())\n",
    "            pred_mask = (targets == pred_label).float()\n",
    "            for i in range(num_class):\n",
    "                class_mask = (targets == i).float()\n",
    "\n",
    "                classwise_correct[i] += (class_mask * pred_mask).sum()\n",
    "                classwise_num[i] += class_mask.sum()\n",
    "\n",
    "             # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            # plot progress\n",
    "            bar.suffix  = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | ' \\\n",
    "                          'Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}'.format(\n",
    "                        batch=batch_idx + 1,\n",
    "                        size=len(valloader),\n",
    "                        data=data_time.avg,\n",
    "                        bt=batch_time.avg,\n",
    "                        total=bar.elapsed_td,\n",
    "                        eta=bar.eta_td,\n",
    "                        loss=losses.avg,\n",
    "                        top1=top1.avg,\n",
    "                        top5=top5.avg,\n",
    "                        )\n",
    "            bar.next()\n",
    "        bar.finish()\n",
    "\n",
    "    # Major, Neutral, Minor\n",
    "    section_num = int(num_class / 3)\n",
    "    classwise_acc = (classwise_correct / classwise_num)\n",
    "    section_acc[0] = classwise_acc[:section_num].mean()\n",
    "    section_acc[2] = classwise_acc[-1 * section_num:].mean()\n",
    "    section_acc[1] = classwise_acc[section_num:-1 * section_num].mean()\n",
    "    GM = 1\n",
    "    for i in range(num_class):\n",
    "        if classwise_acc[i] == 0:\n",
    "            # To prevent the N/A values, we set the minimum value as 0.001\n",
    "            GM *= (1/(100 * num_class)) ** (1/num_class)\n",
    "        else:\n",
    "            GM *= (classwise_acc[i]) ** (1/num_class)\n",
    "\n",
    "    return (losses.avg, classwise_acc.mean().tolist(), section_acc.cpu().numpy(), GM)\n",
    "\n",
    "\n",
    "class WeightEMA(object):\n",
    "    def __init__(self, model, ema_model, alpha=0.999):\n",
    "        self.model = model\n",
    "        self.ema_model = ema_model\n",
    "        self.alpha = alpha\n",
    "        self.params = list(model.state_dict().values())\n",
    "        self.ema_params = list(ema_model.state_dict().values())\n",
    "\n",
    "        for param, ema_param in zip(self.params, self.ema_params):\n",
    "            ema_param.data.copy_(param.data)\n",
    "\n",
    "    def step(self):\n",
    "        one_minus_alpha = 1.0 - self.alpha\n",
    "        for param, ema_param in zip(self.params, self.ema_params):\n",
    "            ema_param = ema_param.float()\n",
    "            param = param.float()\n",
    "            ema_param.mul_(self.alpha)\n",
    "            ema_param.add_(param * one_minus_alpha)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40590fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0febc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ef89b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d644f87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68271d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4578f82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = joblib.load(\"/home/rnittala/Downloads/coco_intra_lt_inter_bl.jbl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d79bfd25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['info', 'patch_id_to_ann_id', 'split', 'attributes', 'type', 'ann_vecs', 'train', 'val', 'test_lt', 'test_bl', 'test_bbl', 'cat2id', 'annotations'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b9d6f069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'This is an intermediate version of the 2016 MS COCO Attributes dataset.',\n",
       " 'url': 'http://cocottributes.org',\n",
       " 'version': '0.5',\n",
       " 'year': 2016,\n",
       " 'contributor': 'MS COCO Attributes group',\n",
       " 'date_created': '2016-04-04 20:06:22.090377'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9fb1e540",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.path.exists(\"scratch/inf0\"):\n",
    "    print(\"Yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cf3282",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GLTSSL",
   "language": "python",
   "name": "gltssl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
